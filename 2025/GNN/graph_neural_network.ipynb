{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (mathematical subjects)\n",
    "subjects = df[\"Subject\"].tolist()\n",
    "G.add_nodes_from(subjects)\n",
    "\n",
    "# Add weighted edges based on TF-IDF similarity\n",
    "threshold = 0.1  # Only add edges for similarity above this threshold\n",
    "for i in range(len(subjects)):\n",
    "    for j in range(i + 1, len(subjects)):\n",
    "        weight = tfidf_similarity[i, j]\n",
    "        if weight > threshold:  # Only add meaningful connections\n",
    "            G.add_edge(subjects[i], subjects[j], weight=weight)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G)  # Positioning nodes\n",
    "edges = G.edges(data=True)\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\", node_size=2000, font_size=10)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f\"{d['weight']:.2f}\" for u, v, d in edges}, font_size=8)\n",
    "\n",
    "# Show the graph\n",
    "plt.title(\"Graph Representation of Mathematical Subject Similarity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PyTorch Geometric is available\n",
    "try:\n",
    "    import torch\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    from torch.nn import functional as F\n",
    "\n",
    "    # Step 1: Convert NetworkX Graph to PyTorch Geometric Data Format\n",
    "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Node Features: Using TF-IDF matrix as initial node features\n",
    "    node_features = torch.tensor(tfidf_matrix.toarray(), dtype=torch.float)\n",
    "\n",
    "    # Create a PyTorch Geometric data object\n",
    "    data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "    # Step 2: Define a Graph Convolutional Network (GCN) Model\n",
    "    class GCN(torch.nn.Module):\n",
    "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "            super(GCN, self).__init__()\n",
    "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    # Step 3: Train the GNN Model\n",
    "    model = GCN(in_channels=node_features.shape[1], hidden_channels=16, out_channels=2)  # 2D embedding\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.mse_loss(out, data.x)  # Simple reconstruction loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    # Train for a few epochs\n",
    "    for epoch in range(200):\n",
    "        loss = train()\n",
    "\n",
    "    # Step 4: Extract Learned Node Embeddings\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x, data.edge_index).numpy()\n",
    "\n",
    "    # Convert embeddings to DataFrame for visualization\n",
    "    embeddings_df = pd.DataFrame(embeddings, index=df[\"Subject\"], columns=[\"Dim1\", \"Dim2\"])\n",
    "\n",
    "    # Display learned embeddings\n",
    "    tools.display_dataframe_to_user(name=\"GNN Learned Embeddings\", dataframe=embeddings_df)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric is not available in this environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PyTorch Geometric is available for advanced GNN implementation\n",
    "try:\n",
    "    import torch\n",
    "    from torch_geometric.nn import GATConv  # Using Graph Attention Networks (GAT)\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.manifold import TSNE\n",
    "    import numpy as np\n",
    "\n",
    "    # Define Graph Attention Network (GAT) Model\n",
    "    class GAT(torch.nn.Module):\n",
    "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "            super(GAT, self).__init__()\n",
    "            self.conv1 = GATConv(in_channels, hidden_channels, heads=4, concat=True)  # Multi-head attention\n",
    "            self.conv2 = GATConv(hidden_channels * 4, out_channels, heads=1, concat=False)  # Output layer\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.elu(x)  # Exponential Linear Unit (ELU) activation\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    # Initialize the GAT model\n",
    "    model = GAT(in_channels=node_features.shape[1], hidden_channels=16, out_channels=4)  # 4D embeddings\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "    def train_gat():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.mse_loss(out, data.x)  # Reconstruction loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    # Train GAT for 300 epochs\n",
    "    for epoch in range(300):\n",
    "        loss = train_gat()\n",
    "\n",
    "    # Extract learned node embeddings\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x, data.edge_index).numpy()\n",
    "\n",
    "    # Step 2: Perform Clustering on Node Embeddings\n",
    "    num_clusters = 3  # Assuming 3 clusters\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Step 3: Project embeddings into 2D space using t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Create a DataFrame to store results\n",
    "    embeddings_df = pd.DataFrame(tsne_embeddings, index=df[\"Subject\"], columns=[\"TSNE_Dim1\", \"TSNE_Dim2\"])\n",
    "    embeddings_df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "    # Display Clustering Results\n",
    "    tools.display_dataframe_to_user(name=\"GAT Clustering Results\", dataframe=embeddings_df)\n",
    "\n",
    "    # Step 4: Visualize 2D embeddings with Clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=cluster_labels, cmap=\"viridis\", s=100, alpha=0.8)\n",
    "    for i, txt in enumerate(df[\"Subject\"]):\n",
    "        plt.annotate(txt, (tsne_embeddings[i, 0], tsne_embeddings[i, 1]), fontsize=10, ha='right')\n",
    "    plt.colorbar(scatter, label=\"Cluster\")\n",
    "    plt.title(\"Mathematical Subject Embeddings (t-SNE Projection)\")\n",
    "    plt.xlabel(\"TSNE Dimension 1\")\n",
    "    plt.ylabel(\"TSNE Dimension 2\")\n",
    "    plt.show()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric is not available in this environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "\n",
    "# Step 1: Perform Clustering on TF-IDF Feature Vectors\n",
    "num_clusters = 3  # Assuming 3 clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(tfidf_matrix.toarray())\n",
    "\n",
    "# Step 2: Reduce Dimensionality Using t-SNE for Visualization\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_embeddings = tsne.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "embeddings_df = pd.DataFrame(tsne_embeddings, index=df[\"Subject\"], columns=[\"TSNE_Dim1\", \"TSNE_Dim2\"])\n",
    "embeddings_df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "# Step 3: Link Prediction using Jaccard Similarity\n",
    "predicted_links = []\n",
    "for u, v in nx.non_edges(G):  # Check pairs that do not have an edge yet\n",
    "    jaccard_coeff = list(nx.jaccard_coefficient(G, [(u, v)]))  # Compute Jaccard Coefficient\n",
    "    if jaccard_coeff and jaccard_coeff[0][2] > 0.1:  # Only keep meaningful links\n",
    "        predicted_links.append((u, v, jaccard_coeff[0][2]))\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "predicted_links_df = pd.DataFrame(predicted_links, columns=[\"Node 1\", \"Node 2\", \"Jaccard Similarity\"])\n",
    "\n",
    "# Display Results\n",
    "tools.display_dataframe_to_user(name=\"Mathematical Subject Clusters\", dataframe=embeddings_df)\n",
    "tools.display_dataframe_to_user(name=\"Predicted Missing Links\", dataframe=predicted_links_df)\n",
    "\n",
    "# Step 4: Visualizing the t-SNE Embeddings with Clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=cluster_labels, cmap=\"coolwarm\", s=100, alpha=0.8)\n",
    "for i, txt in enumerate(df[\"Subject\"]):\n",
    "    plt.annotate(txt, (tsne_embeddings[i, 0], tsne_embeddings[i, 1]), fontsize=10, ha='right')\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.title(\"Mathematical Subject Embeddings (t-SNE Projection)\")\n",
    "plt.xlabel(\"TSNE Dimension 1\")\n",
    "plt.ylabel(\"TSNE Dimension 2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
